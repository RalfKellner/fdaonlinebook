{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The analysis of dependent variables\n",
    "\n",
    "Often in data analysis single variables like e.g., the turnover, the purchase decision of a customer, the repayment of a loan, etc., are in the foreground. This variable is called dependent variable. In addition to the raw analysis of this variable, the influence of other variables on the dependent variable is often important. For example, it is of great interest to a company which influencing factors are decisive for the company's sales. These variables are called independent variables, predictors or feature variables. In order to analyze the possible influence of the independent variables on the dependent variable, a model-based approach is very often chosen, in which an attempt is made to predict the dependent variable as well as possible by means of a model and the choice of suitable independent variables, and to explain it in this way. At an abstract level, most models for the dependent variable $y$ using the independent variables $x_1, x_2, ..., x_p$ look like the following:\n",
    "\n",
    "$$\n",
    "y = f\\left(x_1, x_2, ..., x_p\\right) + \\epsilon\n",
    "$$\n",
    "\n",
    "The equation states that $y$ is divided into a functional relationship $f$ between the independent variables $x_1, x_2, ..., x_p$ and $y$ and a (random) deviation. The functional relationship is defined differently depending on the model, but it represents the deterministic part of the model. The random part of the observation $\\epsilon$ represents the random deviation from the explainable part of the model. This can actually be caused by pure randomness or partly result from an inadequate choice for $f$. \n",
    "\n",
    "If one wants to investigate the potential influence of the independent variable on the dependent variable with the help of a model, a concrete specification for $f$ is required. Subsequently, a model is trained and evaluated with the data of a sample. The evaluation has the main purpose to check how well the model is able to explain the occurrence of the realizations of $y$. Ultimately, inferences based on a model only make sense if the model is able to represent reality approximately well. If it gets to this point, the trained model can be used to analyze in detail the questions about the influences of the independent variables and the importance of these. \n",
    "\n",
    "In the next chapters we will look at comparatively simpler models that can be used for differently scaled dependent variables. We begin with the case where $y$ is a numerical variable. We then look at models for categorical variables, starting with variables and two categories and then looking at the case for multiple categories. After these chapters, commonalities in structuring and estimating the models, as well as in evaluating the estimated models, should become clear. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
